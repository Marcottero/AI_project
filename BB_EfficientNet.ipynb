{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/gdrive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UjSXVevTSPiU",
        "outputId": "ad286691-8c3c-4412-c960-18137c07e6a5"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython import get_ipython\n",
        "from IPython.display import display"
      ],
      "metadata": {
        "id": "GIPk98PxpFrG"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install efficientnet_pytorch"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uX1ZDTwohay4",
        "outputId": "a8277055-88fc-408a-f545-6d37ab46254e"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting efficientnet_pytorch\n",
            "  Downloading efficientnet_pytorch-0.7.1.tar.gz (21 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (from efficientnet_pytorch) (2.6.0+cu124)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch->efficientnet_pytorch) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch->efficientnet_pytorch) (4.13.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch->efficientnet_pytorch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch->efficientnet_pytorch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch->efficientnet_pytorch) (2025.3.2)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch->efficientnet_pytorch)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch->efficientnet_pytorch)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch->efficientnet_pytorch)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch->efficientnet_pytorch)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch->efficientnet_pytorch)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch->efficientnet_pytorch)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch->efficientnet_pytorch)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch->efficientnet_pytorch)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch->efficientnet_pytorch)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch->efficientnet_pytorch) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch->efficientnet_pytorch) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->efficientnet_pytorch) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch->efficientnet_pytorch)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch->efficientnet_pytorch) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch->efficientnet_pytorch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch->efficientnet_pytorch) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch->efficientnet_pytorch) (3.0.2)\n",
            "Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m124.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m95.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m56.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m18.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m73.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: efficientnet_pytorch\n",
            "  Building wheel for efficientnet_pytorch (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for efficientnet_pytorch: filename=efficientnet_pytorch-0.7.1-py3-none-any.whl size=16426 sha256=28e8459a2a503de532533b7f4e8163b698c1fa034eb9e1b5047c1e4da61be506\n",
            "  Stored in directory: /root/.cache/pip/wheels/8b/6f/9b/231a832f811ab6ebb1b32455b177ffc6b8b1cd8de19de70c09\n",
            "Successfully built efficientnet_pytorch\n",
            "Installing collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, efficientnet_pytorch\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "Successfully installed efficientnet_pytorch-0.7.1 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torchvision import transforms\n",
        "from efficientnet_pytorch import EfficientNet\n",
        "import numpy as np\n",
        "from typing import Dict, List, Tuple, Optional"
      ],
      "metadata": {
        "id": "OPSuIfUTSMjT"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class EfficientNetBackbone2D(nn.Module):\n",
        "    \"\"\"\n",
        "    Backbone EfficientNet per analisi multi-modale di tavole tecniche 2D.\n",
        "    Rileleva errori in saldature, cartiglio e BOM.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        model_name: str = 'efficientnet-b0',\n",
        "        num_classes: int = 6,  # missing_weld, weld_error, valid_name, des_name, mat_cod, part_cod\n",
        "        freeze_layers: int = 3,  # Numero di blocchi da congelare\n",
        "        dropout_rate: float = 0.2,\n",
        "        pretrained: bool = True\n",
        "    ):\n",
        "        super(EfficientNetBackbone2D, self).__init__()\n",
        "\n",
        "        self.num_classes = num_classes\n",
        "        self.class_names = [\n",
        "            'missing_weld',    # 0: Simboli di saldatura mancanti\n",
        "            'weld_error',      # 1: Simboli di saldatura posizionati male\n",
        "            'valid_name',      # 2: Nome validatore presente e corretto\n",
        "            'des_name',        # 3: Nome disegnatore presente\n",
        "            'mat_cod',         # 4: Codice materiale presente\n",
        "            'part_cod'         # 5: Codice parte presente\n",
        "        ]\n",
        "\n",
        "        # Carica EfficientNet pre-addestrata\n",
        "        if pretrained:\n",
        "            self.backbone = EfficientNet.from_pretrained(model_name)\n",
        "        else:\n",
        "            self.backbone = EfficientNet.from_name(model_name)\n",
        "\n",
        "        # Ottieni il numero di features dell'ultimo layer\n",
        "        self.num_features = self.backbone._fc.in_features\n",
        "\n",
        "        # Rimuovi il classificatore originale\n",
        "        self.backbone._fc = nn.Identity()\n",
        "\n",
        "        # Congela i primi layer\n",
        "        self._freeze_layers(freeze_layers)\n",
        "\n",
        "        # Feature extractor custom per le diverse regioni\n",
        "        # Modificato: removed redundant pooling/flatten layers from the attention module itself\n",
        "        self.region_attention = nn.ModuleDict({\n",
        "            'weld_region': self._create_attention_module(),\n",
        "            'title_block': self._create_attention_module(),\n",
        "            'bom_region': self._create_attention_module()\n",
        "        })\n",
        "\n",
        "        # Classificatori specifici per ogni tipo di errore\n",
        "        self.classifiers = nn.ModuleDict({\n",
        "            # Classificatori per errori di saldatura\n",
        "            'weld_classifier': self._create_classifier(self.num_features, 2, dropout_rate),  # missing_weld, weld_error\n",
        "\n",
        "            # Classificatori per cartiglio\n",
        "            'title_classifier': self._create_classifier(self.num_features, 2, dropout_rate),  # valid_name, des_name\n",
        "\n",
        "            # Classificatori per BOM\n",
        "            'bom_classifier': self._create_classifier(self.num_features, 2, dropout_rate)     # mat_cod, part_cod\n",
        "        })\n",
        "\n",
        "        # Classificatore finale multi-label\n",
        "        self.final_classifier = nn.Sequential(\n",
        "            nn.Linear(self.num_features, 512),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(dropout_rate),\n",
        "            nn.Linear(512, 256),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(dropout_rate),\n",
        "            nn.Linear(256, num_classes)\n",
        "        )\n",
        "\n",
        "        # Loss weights per bilanciare le classi\n",
        "        self.loss_weights = torch.tensor([1.2, 1.0, 0.8, 0.8, 1.0, 1.0])  # Peso maggiore per errori critici\n",
        "\n",
        "    def _freeze_layers(self, freeze_layers: int):\n",
        "        \"\"\"Congela i primi N blocchi della rete\"\"\"\n",
        "        blocks_to_freeze = min(freeze_layers, len(self.backbone._blocks))\n",
        "\n",
        "        # Congela stem (primo layer)\n",
        "        for param in self.backbone._conv_stem.parameters():\n",
        "            param.requires_grad = False\n",
        "        for param in self.backbone._bn0.parameters():\n",
        "            param.requires_grad = False\n",
        "\n",
        "        # Congela i primi N blocchi\n",
        "        for i in range(blocks_to_freeze):\n",
        "            for param in self.backbone._blocks[i].parameters():\n",
        "                param.requires_grad = False\n",
        "\n",
        "        print(f\"Congelati i primi {blocks_to_freeze} blocchi + stem layer\")\n",
        "\n",
        "    def _create_attention_module(self):\n",
        "        \"\"\"Crea un modulo di attenzione per le regioni specifiche.\n",
        "        Applica solo i layer lineari e l'attivazione,\n",
        "        poiché l'input è già pre-poolato e appiattito.\"\"\"\n",
        "        return nn.Sequential(\n",
        "            # Rimosso AdaptiveAvgPool2d e Flatten da qui\n",
        "            nn.Linear(self.num_features, self.num_features // 4),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(self.num_features // 4, self.num_features),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "    def _create_classifier(self, in_features: int, out_features: int, dropout_rate: float):\n",
        "        \"\"\"Crea un classificatore specifico\"\"\"\n",
        "        return nn.Sequential(\n",
        "            nn.Linear(in_features, in_features // 2),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(dropout_rate),\n",
        "            nn.Linear(in_features // 2, out_features)\n",
        "        )\n",
        "\n",
        "    def forward(self, x: torch.Tensor, region_masks: Optional[Dict[str, torch.Tensor]] = None):\n",
        "        \"\"\"\n",
        "        Forward pass con attenzione alle regioni\n",
        "\n",
        "        Args:\n",
        "            x: Input tensor (B, C, H, W)\n",
        "            region_masks: Dict con maschere per le diverse regioni (opzionale)\n",
        "\n",
        "        Returns:\n",
        "            Dict con le predizioni per ogni categoria\n",
        "        \"\"\"\n",
        "        # Estrazione features dalla backbone\n",
        "        features = self.backbone.extract_features(x)  # (B, C, H_feat, W_feat)\n",
        "\n",
        "        # Get the spatial dimensions of the feature map\n",
        "        _, _, H_feat, W_feat = features.shape\n",
        "\n",
        "        # Global average pooling\n",
        "        global_features = F.adaptive_avg_pool2d(features, 1).flatten(1)  # (B, num_features)\n",
        "\n",
        "        # Applicazione dell'attenzione alle regioni (se fornite le maschere)\n",
        "        region_features = {}\n",
        "        if region_masks is not None:\n",
        "            # Resize masks to match feature map size and move to the correct device\n",
        "            resized_masks = {}\n",
        "            for region_name, mask in region_masks.items():\n",
        "                if region_name in self.region_attention:\n",
        "                    # Ensure mask is on the correct device\n",
        "                    mask = mask.to(features.device)\n",
        "                    # Resize mask to feature map spatial dimensions\n",
        "                    # Add a channel dimension to the mask before interpolation\n",
        "                    resized_mask = F.interpolate(mask.unsqueeze(1), size=(H_feat, W_feat), mode='bilinear', align_corners=False)\n",
        "                    # Remove the channel dimension and ensure it's float for multiplication\n",
        "                    resized_masks[region_name] = resized_mask.squeeze(1).float()\n",
        "\n",
        "            for region_name, resized_mask in resized_masks.items():\n",
        "                if region_name in self.region_attention:\n",
        "                    # Applica maschera alle features\n",
        "                    # Resized mask shape: (B, H_feat, W_feat)\n",
        "                    # Features shape: (B, C, H_feat, W_feat)\n",
        "                    # Unsqueeze mask for broadcasting with features: (B, 1, H_feat, W_feat)\n",
        "                    masked_features = features * resized_mask.unsqueeze(1)\n",
        "\n",
        "                    # Pool and flatten the masked features BEFORE passing to the attention module\n",
        "                    pooled = F.adaptive_avg_pool2d(masked_features, 1).view(masked_features.size(0), -1) # (B, num_features)\n",
        "\n",
        "                    # Calcola attenzione\n",
        "                    # Now pooled (B, num_features) is passed directly to the attention linear layers\n",
        "                    attention = self.region_attention[region_name](pooled)\n",
        "                    region_features[region_name] = pooled * attention\n",
        "\n",
        "\n",
        "        # Classificazioni specifiche\n",
        "        predictions = {}\n",
        "\n",
        "        # Classificazione saldature\n",
        "        # Ensure regions are present in region_features before accessing\n",
        "        if 'weld_region' in region_features:\n",
        "            weld_preds = self.classifiers['weld_classifier'](region_features['weld_region'])\n",
        "            predictions['weld_missing'] = weld_preds[:, 0]\n",
        "            predictions['weld_error'] = weld_preds[:, 1]\n",
        "\n",
        "        # Classificazione cartiglio\n",
        "        if 'title_block' in region_features:\n",
        "            title_preds = self.classifiers['title_classifier'](region_features['title_block'])\n",
        "            predictions['valid_name'] = title_preds[:, 0]\n",
        "            predictions['des_name'] = title_preds[:, 1]\n",
        "\n",
        "        # Classificazione BOM\n",
        "        if 'bom_region' in region_features:\n",
        "            bom_preds = self.classifiers['bom_classifier'](region_features['bom_region'])\n",
        "            predictions['mat_cod'] = bom_preds[:, 0]\n",
        "            predictions['part_cod'] = bom_preds[:, 1]\n",
        "\n",
        "        # Classificazione finale multi-label\n",
        "        final_logits = self.final_classifier(global_features)\n",
        "\n",
        "        # Organizza output finale\n",
        "        output = {\n",
        "            'logits': final_logits,\n",
        "            'probabilities': torch.sigmoid(final_logits),\n",
        "            'region_predictions': predictions,\n",
        "            'global_features': global_features\n",
        "        }\n",
        "\n",
        "        return output\n",
        "\n",
        "\n",
        "    def compute_loss(self, outputs: Dict, targets: torch.Tensor, region_targets: Optional[Dict] = None):\n",
        "        \"\"\"\n",
        "        Calcola la loss combinata per tutti i task\n",
        "\n",
        "        Args:\n",
        "            outputs: Output del modello\n",
        "            targets: Target multi-label (B, num_classes)\n",
        "            region_targets: Target specifici per regione (opzionale)\n",
        "        \"\"\"\n",
        "        # Loss principale multi-label\n",
        "        main_loss = F.binary_cross_entropy_with_logits(\n",
        "            outputs['logits'],\n",
        "            targets.float(),\n",
        "            weight=self.loss_weights.to(targets.device)\n",
        "        )\n",
        "\n",
        "        total_loss = main_loss\n",
        "        loss_components = {'main_loss': main_loss.item()}\n",
        "\n",
        "        # Loss aggiuntive per le regioni specifiche\n",
        "        if region_targets and 'region_predictions' in outputs:\n",
        "            region_loss = 0\n",
        "            count = 0\n",
        "\n",
        "            # Mappa i nomi delle predizioni regionali ai nomi dei target regionali\n",
        "            # Le chiavi di outputs['region_predictions'] sono 'weld_missing', 'weld_error', 'valid_name', etc.\n",
        "            # Le chiavi di region_targets dovrebbero essere i nomi delle regioni 'weld_region', 'title_block', etc.\n",
        "            # Dobbiamo assicurarci che i target per 'weld_missing' e 'weld_error'\n",
        "            # siano mappati correttamente al target di 'weld_region', ecc.\n",
        "\n",
        "            # Creiamo una mappa inversa per facilitare la ricerca dei target\n",
        "            # Questo approccio potrebbe non essere ideale se i target regionali\n",
        "            # non corrispondono direttamente 1-a-1 con i sottotask (es. un target per 'weld_region'\n",
        "            # che si applica sia a 'missing_weld' che a 'weld_error').\n",
        "            # Assumiamo che region_targets contenga i target per i task specifici\n",
        "            # 'missing_weld', 'weld_error', 'valid_name', 'des_name', 'mat_cod', 'part_cod'\n",
        "            # filtrati per le regioni.\n",
        "\n",
        "            # Rivediamo la logica: i classificatori regionali hanno 2 output ciascuno.\n",
        "            # 'weld_classifier' -> ['weld_missing', 'weld_error']\n",
        "            # 'title_classifier' -> ['valid_name', 'des_name']\n",
        "            # 'bom_classifier' -> ['mat_cod', 'part_cod']\n",
        "            # I region_targets dovrebbero avere le stesse chiavi dei task finali\n",
        "            # ma solo per quelli coperti dai classificatori regionali.\n",
        "            # Es: region_targets = {'missing_weld': target_tensor_0, 'weld_error': target_tensor_1, ...}\n",
        "\n",
        "            # Controlliamo se region_targets contiene le chiavi delle predizioni regionali\n",
        "            regional_task_keys = {\n",
        "                'weld_classifier': ['weld_missing', 'weld_error'],\n",
        "                'title_classifier': ['valid_name', 'des_name'],\n",
        "                'bom_classifier': ['mat_cod', 'part_cod']\n",
        "            }\n",
        "\n",
        "            for classifier_name, task_keys in regional_task_keys.items():\n",
        "                if classifier_name in self.classifiers: # Ensure the classifier exists\n",
        "                     # Get the raw predictions from the specific classifier\n",
        "                     # We need the output BEFORE splitting into missing/error etc.\n",
        "                     # This requires modifying the forward pass to store classifier outputs\n",
        "                     # or recalculating here. Let's modify forward to store these if needed.\n",
        "\n",
        "                     # Assuming region_predictions already stores the *split* predictions\n",
        "                     # we need to map them back or adjust the target handling.\n",
        "                     # If region_targets has keys 'weld_missing', 'weld_error', etc.\n",
        "                    valid_regional_preds = []\n",
        "                    valid_regional_targets = []\n",
        "                    current_region_loss = 0\n",
        "                    current_region_count = 0\n",
        "\n",
        "                    for task_key in task_keys:\n",
        "                        if task_key in outputs['region_predictions'] and task_key in region_targets:\n",
        "                             # Ensure shapes match - region_preds[:, i] has shape (B,)\n",
        "                             # region_targets[task_key] should also have shape (B,)\n",
        "                            if outputs['region_predictions'][task_key].shape == region_targets[task_key].shape:\n",
        "                                reg_loss = F.binary_cross_entropy_with_logits(\n",
        "                                    outputs['region_predictions'][task_key],\n",
        "                                    region_targets[task_key].float()\n",
        "                                )\n",
        "                                current_region_loss += reg_loss\n",
        "                                current_region_count += 1\n",
        "                            else:\n",
        "                                print(f\"Warning: Shape mismatch for regional target '{task_key}'. Pred shape: {outputs['region_predictions'][task_key].shape}, Target shape: {region_targets[task_key].shape}\")\n",
        "\n",
        "                    if current_region_count > 0:\n",
        "                        # Average loss for the tasks associated with this classifier\n",
        "                        avg_classifier_loss = current_region_loss / current_region_count\n",
        "                        region_loss += avg_classifier_loss\n",
        "                        count += 1 # Increment overall region count based on classifiers with valid targets\n",
        "\n",
        "            if count > 0:\n",
        "                # Average loss across the classifiers that had valid targets\n",
        "                region_loss /= count\n",
        "                total_loss += 0.3 * region_loss  # Peso minore per le loss regionali\n",
        "                loss_components['region_loss'] = region_loss.item()\n",
        "                # Optionally add individual classifier losses\n",
        "                # loss_components['weld_classifier_loss'] = ...\n",
        "                # loss_components['title_classifier_loss'] = ...\n",
        "                # loss_components['bom_classifier_loss'] = ...\n",
        "\n",
        "\n",
        "        return total_loss, loss_components\n",
        "\n",
        "    def predict(self, x: torch.Tensor, region_masks: Optional[Dict[str, torch.Tensor]] = None, threshold: float = 0.5) -> Dict:\n",
        "        \"\"\"\n",
        "        Predizione con soglia per classificazione binaria\n",
        "\n",
        "        Args:\n",
        "            x: Input tensor\n",
        "            region_masks: Dict con maschere per le diverse regioni (opzionale)\n",
        "            threshold: Soglia per la classificazione binaria\n",
        "\n",
        "        Returns:\n",
        "            Dict con predizioni e confidenze per ogni categoria\n",
        "            Include anche predizioni e confidenze per le regioni specifiche\n",
        "        \"\"\"\n",
        "        self.eval()\n",
        "        with torch.no_grad():\n",
        "            # Pass region_masks to the forward method\n",
        "            outputs = self.forward(x, region_masks)\n",
        "\n",
        "            # Global predictions\n",
        "            global_probs = outputs['probabilities']\n",
        "            global_predictions = (global_probs > threshold).int()\n",
        "\n",
        "            # Organize global results\n",
        "            results = {'global': {}}\n",
        "            for i, class_name in enumerate(self.class_names):\n",
        "                results['global'][class_name] = {\n",
        "                    'prediction': global_predictions[:, i].cpu().numpy(),\n",
        "                    'confidence': global_probs[:, i].cpu().numpy()\n",
        "                }\n",
        "\n",
        "            # Regional predictions\n",
        "            results['regional'] = {}\n",
        "            if 'region_predictions' in outputs:\n",
        "                 for task_name, logits in outputs['region_predictions'].items():\n",
        "                     regional_probs = torch.sigmoid(logits)\n",
        "                     regional_preds = (regional_probs > threshold).int()\n",
        "                     results['regional'][task_name] = {\n",
        "                         'prediction': regional_preds.cpu().numpy(),\n",
        "                         'confidence': regional_probs.cpu().numpy()\n",
        "                     }\n",
        "\n",
        "\n",
        "            return results\n",
        "\n",
        "    def get_trainable_parameters(self):\n",
        "        \"\"\"Restituisce solo i parametri allenabili\"\"\"\n",
        "        return [p for p in self.parameters() if p.requires_grad]\n",
        "\n",
        "    def unfreeze_all(self):\n",
        "        \"\"\"Sblocca tutti i parametri per fine-tuning completo\"\"\"\n",
        "        for param in self.parameters():\n",
        "            param.requires_grad = True\n",
        "        print(\"Tutti i parametri sono stati sbloccati\")\n",
        "\n",
        "\n",
        "# Utility per preprocessing delle immagini\n",
        "class DrawingPreprocessor:\n",
        "    \"\"\"Preprocessor specifico per tavole tecniche\"\"\"\n",
        "\n",
        "    def __init__(self, input_size: Tuple[int, int] = (512, 512)):\n",
        "        self.input_size = input_size\n",
        "\n",
        "        # Transform per training\n",
        "        self.train_transform = transforms.Compose([\n",
        "            transforms.Resize(input_size),\n",
        "            transforms.RandomRotation(degrees=(-2, 2)),  # Rotazione minima\n",
        "            transforms.RandomAffine(degrees=0, translate=(0.02, 0.02)),  # Traslazione minima\n",
        "            transforms.ColorJitter(brightness=0.1, contrast=0.1),  # Variazione minima di contrasto\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "        ])\n",
        "\n",
        "        # Transform per validazione/test\n",
        "        self.val_transform = transforms.Compose([\n",
        "            transforms.Resize(input_size),\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "        ])\n",
        "\n",
        "    def create_region_masks(self, image_size: Tuple[int, int]) -> Dict[str, np.ndarray]:\n",
        "        \"\"\"\n",
        "        Crea maschere approssimative per le diverse regioni della tavola\n",
        "\n",
        "        Args:\n",
        "            image_size: (height, width) dell'immagine\n",
        "\n",
        "        Returns:\n",
        "            Dict con maschere per ogni regione\n",
        "        \"\"\"\n",
        "        h, w = image_size\n",
        "        masks = {}\n",
        "\n",
        "        # Maschera per regione saldature (parte centrale-superiore)\n",
        "        weld_mask = np.zeros((h, w), dtype=np.float32)\n",
        "        weld_mask[h//6:2*h//3, w//6:5*w//6] = 1.0\n",
        "        masks['weld_region'] = weld_mask\n",
        "\n",
        "        # Maschera per cartiglio (angolo basso-destro)\n",
        "        title_mask = np.zeros((h, w), dtype=np.float32)\n",
        "        title_mask[3*h//4:, 2*w//3:] = 1.0\n",
        "        masks['title_block'] = title_mask\n",
        "\n",
        "        # Maschera per BOM (lato destro)\n",
        "        bom_mask = np.zeros((h, w), dtype=np.float32)\n",
        "        bom_mask[h//6:2*h//3, 3*w//4:] = 1.0\n",
        "        masks['bom_region'] = bom_mask\n",
        "\n",
        "        return masks\n",
        "\n",
        "\n",
        "# Esempio di utilizzo\n",
        "def create_model_and_example():\n",
        "    \"\"\"Esempio di creazione e utilizzo del modello\"\"\"\n",
        "\n",
        "    # Crea il modello\n",
        "    model = EfficientNetBackbone2D(\n",
        "        model_name='efficientnet-b0',\n",
        "        num_classes=6,\n",
        "        freeze_layers=3,\n",
        "        dropout_rate=0.2,\n",
        "        pretrained=True\n",
        "    )\n",
        "\n",
        "    print(f\"Modello creato con {sum(p.numel() for p in model.parameters())} parametri totali\")\n",
        "    print(f\"Parametri allenabili: {sum(p.numel() for p in model.get_trainable_parameters())}\")\n",
        "\n",
        "    # Esempio di input\n",
        "    batch_size = 4\n",
        "    input_tensor = torch.randn(batch_size, 3, 512, 512)\n",
        "\n",
        "    # Crea maschere di esempio\n",
        "    preprocessor = DrawingPreprocessor()\n",
        "    region_masks = preprocessor.create_region_masks((512, 512))\n",
        "\n",
        "    # Converti maschere in tensor e aggiungi batch dimension\n",
        "    mask_tensors = {}\n",
        "    for region, mask in region_masks.items():\n",
        "        # mask is np array (H, W), convert to tensor (H, W), unsqueeze to (1, H, W), repeat batch_size times (B, H, W)\n",
        "        mask_tensors[region] = torch.from_numpy(mask).unsqueeze(0).repeat(batch_size, 1, 1)\n",
        "\n",
        "    # Forward pass\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        # Pass mask_tensors to the forward method\n",
        "        outputs = model(input_tensor, mask_tensors)\n",
        "\n",
        "    print(f\"Shape output logits: {outputs['logits'].shape}\")\n",
        "    print(f\"Shape probabilità: {outputs['probabilities'].shape}\")\n",
        "    print(f\"Classi: {model.class_names}\")\n",
        "\n",
        "    # Esempio di calcolo della loss (necessita di target)\n",
        "    # Crea target di esempio (random per dimostrazione)\n",
        "    dummy_targets = torch.randint(0, 2, (batch_size, model.num_classes)).float() # Random binary targets\n",
        "    # Crea target regionali di esempio - devono corrispondere alle task regionali\n",
        "    dummy_region_targets = {\n",
        "        'weld_missing': torch.randint(0, 2, (batch_size,)).float(),\n",
        "        'weld_error': torch.randint(0, 2, (batch_size,)).float(),\n",
        "        'valid_name': torch.randint(0, 2, (batch_size,)).float(),\n",
        "        'des_name': torch.randint(0, 2, (batch_size,)).float(),\n",
        "        'mat_cod': torch.randint(0, 2, (batch_size,)).float(),\n",
        "        'part_cod': torch.randint(0, 2, (batch_size,)).float(),\n",
        "    }\n",
        "\n",
        "    total_loss, loss_components = model.compute_loss(outputs, dummy_targets, dummy_region_targets)\n",
        "    print(f\"\\nTotal Loss: {total_loss.item()}\")\n",
        "    print(f\"Loss Components: {loss_components}\")\n",
        "\n",
        "    # Esempio di predizione (con soglia)\n",
        "    predictions_results = model.predict(input_tensor, mask_tensors)\n",
        "    print(\"\\nPrediction Results (Global):\")\n",
        "    for class_name, data in predictions_results['global'].items():\n",
        "        print(f\"  {class_name}: Prediction={data['prediction']}, Confidence={data['confidence']}\")\n",
        "\n",
        "    print(\"\\nPrediction Results (Regional):\")\n",
        "    for task_name, data in predictions_results['regional'].items():\n",
        "         print(f\"  {task_name}: Prediction={data['prediction']}, Confidence={data['confidence']}\")\n",
        "\n",
        "\n",
        "    return model, preprocessor\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    model, preprocessor = create_model_and_example()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gLWdYYjapZ6S",
        "outputId": "a712ebee-8a37-4915-ba2f-7b4b6fd8468d"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded pretrained weights for efficientnet-b0\n",
            "Congelati i primi 3 blocchi + stem layer\n",
            "Modello creato con 9722056 parametri totali\n",
            "Parametri allenabili: 9702966\n",
            "Shape output logits: torch.Size([4, 6])\n",
            "Shape probabilità: torch.Size([4, 6])\n",
            "Classi: ['missing_weld', 'weld_error', 'valid_name', 'des_name', 'mat_cod', 'part_cod']\n",
            "\n",
            "Total Loss: 0.8782455921173096\n",
            "Loss Components: {'main_loss': 0.6702383160591125, 'region_loss': 0.6933574676513672}\n",
            "\n",
            "Prediction Results (Global):\n",
            "  missing_weld: Prediction=[0 0 0 0], Confidence=[0.47620454 0.4771901  0.47639662 0.47755376]\n",
            "  weld_error: Prediction=[1 1 1 1], Confidence=[0.5087033  0.5089917  0.50880814 0.50924736]\n",
            "  valid_name: Prediction=[1 1 1 1], Confidence=[0.5256676  0.52720386 0.52708864 0.52630985]\n",
            "  des_name: Prediction=[1 1 1 1], Confidence=[0.5077051  0.50663555 0.5076995  0.5056138 ]\n",
            "  mat_cod: Prediction=[0 0 0 0], Confidence=[0.49432546 0.49603495 0.49490675 0.49518895]\n",
            "  part_cod: Prediction=[1 1 1 1], Confidence=[0.51192087 0.51194227 0.5122345  0.51102567]\n",
            "\n",
            "Prediction Results (Regional):\n",
            "  weld_missing: Prediction=[1 1 1 1], Confidence=[0.50360286 0.5042274  0.504222   0.5037363 ]\n",
            "  weld_error: Prediction=[1 0 1 1], Confidence=[0.50064284 0.49978086 0.5003793  0.5004939 ]\n",
            "  valid_name: Prediction=[0 0 0 0], Confidence=[0.49455354 0.494234   0.4939426  0.49419156]\n",
            "  des_name: Prediction=[0 0 0 0], Confidence=[0.49868247 0.49859437 0.49848095 0.49834338]\n",
            "  mat_cod: Prediction=[0 0 0 0], Confidence=[0.4979647  0.49823463 0.4981109  0.4978568 ]\n",
            "  part_cod: Prediction=[1 1 1 1], Confidence=[0.5008757 0.5007899 0.500838  0.5006111]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "PVin4h91RnJ6"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}